---
title: "11组展示R代码"
output: html_document
date: "2025-06-11"
---
#数据处理前准备
```{r}
#加载必要的包
if (!requireNamespace('pacman', quietly = TRUE)) {
  install.packages('pacman')
}

pacman::p_load(
  sqldf, doBy, lme4,lmerTest, emmeans,MASS,crayon,plyr,ggplot2, grid,gridExtra,cowplot,jtools,dplyr)

options(scipen=99999,digits = 5)

#以下为原代码方法
# install.packages("modelr", dependencies = TRUE)
# install.packages("doBy", dependencies = TRUE)
# install.packages("forcats")
# install.packages("jtools")
# library(sqldf)
# library(doBy)
# library(lme4) # for lmer
# library(lmerTest) # for glmer.nb
# library(emmeans)
# library(MASS) # for glm.nb
# library(crayon)
# library(plyr)
# library(ggplot2)
# library(grid) # for creating panels of plots
# library(gridExtra) # for creating panels of plots
# library(cowplot) # for separating legend from plot
# library(jtools)
```

```{r}
#导入数据文件
dfs2_general <- bruceR::import(here::here("data_general_osf.csv"))
dfs2_daily <- bruceR::import(here::here("data_daily_osf.csv"))

# 以下为原代码方法
# dInput <- "F:/homeworkR/"
# dFigures <- "F:/homeworkR/"
# dfs2_general <- read.csv(paste(dInput,"data_general_osf.csv", sep=""), sep=";")
# dfs2_daily <- read.csv(paste(dInput,"data_daily_osf.csv", sep=""), sep=";")
```

#数据预处理
```{r}
#general数据处理#

#使用SQL语法筛选数据
#排除没有完成至少 4 天任务的人+被发现“撒谎”说完成了任务但没完成的人
#排除了自述重大事件影响状态的被试（这一步先前已经完成）
dfs2_general_filtered <- sqldf("select * from dfs2_general 
             where T_Completed_NumDays>=4
             AND ES_Honesty_NoMission=0")
nrow(dfs2_general_filtered)
```


```{r}
#对研究开始时的对话数量进行异常值处理
#设置 2/2.5/3 标准差的上限作为异常值门槛
limit2sd <- mean(dfs2_general_filtered$SS_NumConvos_LastWk_Clean,na.rm=TRUE)+2*sd(dfs2_general_filtered$SS_NumConvos_LastWk_Clean,na.rm=TRUE)
limit25sd <- mean(dfs2_general_filtered$SS_NumConvos_LastWk_Clean,na.rm=TRUE)+2.5*sd(dfs2_general_filtered$SS_NumConvos_LastWk_Clean,na.rm=TRUE)
limit3sd <- mean(dfs2_general_filtered$SS_NumConvos_LastWk_Clean,na.rm=TRUE)+3*sd(dfs2_general_filtered$SS_NumConvos_LastWk_Clean,na.rm=TRUE)
#创建新的变量来标记这些异常值（2、2.5、3个标准差）
dfs2_general_filtered$SS_NumConvos_LastWk_Clean_Trim2SD <- ifelse(dfs2_general_filtered$SS_NumConvos_LastWk_Clean<=limit2sd, dfs2_general_filtered$SS_NumConvos_LastWk_Clean, NA)
dfs2_general_filtered$SS_NumConvos_LastWk_Clean_Trim25SD <- ifelse(dfs2_general_filtered$SS_NumConvos_LastWk_Clean<=limit25sd, dfs2_general_filtered$SS_NumConvos_LastWk_Clean, NA)
dfs2_general_filtered$SS_NumConvos_LastWk_Clean_Trim3SD <- ifelse(dfs2_general_filtered$SS_NumConvos_LastWk_Clean<=limit3sd, dfs2_general_filtered$SS_NumConvos_LastWk_Clean, NA)

#对研究随访阶段的对话数量进行异常值处理
#设置 2/2.5/3 标准差的上限作为异常值门槛
limit2sd <- mean(dfs2_general_filtered$FU_NumConvos_Clean,na.rm=TRUE)+2*sd(dfs2_general_filtered$FU_NumConvos_Clean,na.rm=TRUE)
limit25sd <- mean(dfs2_general_filtered$FU_NumConvos_Clean,na.rm=TRUE)+2.5*sd(dfs2_general_filtered$FU_NumConvos_Clean,na.rm=TRUE)
limit3sd <- mean(dfs2_general_filtered$FU_NumConvos_Clean,na.rm=TRUE)+3*sd(dfs2_general_filtered$FU_NumConvos_Clean,na.rm=TRUE)
#创建新的变量来标记这些异常值（2、2.5、3个标准差）
dfs2_general_filtered$FU_NumConvos_LastWk_Clean_Trim2SD <- ifelse(dfs2_general_filtered$FU_NumConvos_Clean<=limit2sd, dfs2_general_filtered$FU_NumConvos_Clean, NA)
dfs2_general_filtered$FU_NumConvos_LastWk_Clean_Trim25SD <- ifelse(dfs2_general_filtered$FU_NumConvos_Clean<=limit25sd, dfs2_general_filtered$FU_NumConvos_Clean, NA)
dfs2_general_filtered$FU_NumConvos_LastWk_Clean_Trim3SD <- ifelse(dfs2_general_filtered$FU_NumConvos_Clean<=limit3sd, dfs2_general_filtered$FU_NumConvos_Clean, NA)

```

```{r}
#将数据集从宽格式转换为长格式
#每人一行变成每人三行，拼接三个时间点time的数据（1=start, 2=end, 3=follow up）
dfs2_general_filtered_long <- sqldf("
    select 1 as Time, GooseChaseId_Fixed, Uni,T_Condition2,T_Condition3,
      SS_Demog_Age,SS_Demog_SexFemale,
      SS_Trait_SocConn_Avg7 as SS_Trait_SocConn_Avg,
      SS_Trait_SHS_Avg7 as SS_Trait_SHS_Avg,
      SS_SocialCuriosity_Avg,SS_InteractionAnxiety_Avg,SS_Shy_Avg,SS_SelfEsteem_Avg,
      SS_Predict_NumToApp_Clean as NumApp,SS_Predict_Reject_Clean as Reject,SS_Predict_ConvoLen_Clean as ConvoLen,
      SS_Predict_Study_ValAroConn_Avg ValAroConn, 
      SS_General_Ability_Avg7 as Ability,
      SS_HardStart as HardStart,SS_HardStart_rev as AbleStart,
      SS_HardMaintain as HardMaintain,SS_HardMaintain_rev as AbleMaintain,
      SS_HardEnd as HardEnd,SS_HardEnd_rev as AbleEnd,
      SS_General_Awk_Avg7 as Awk_Avg,SS_General_Enj_Avg7 as Enj_Avg, 
      SS_General_PartnerPerception_Avg7 as PartnerPerception,
      SS_DV_Avg_z as DV_Avg_z,
      SS_Strangers_Trust as Strangers_Trust,SS_Strangers_FeelWarmly as Strangers_FeelWarmly,SS_Strangers_FeelConnected as Strangers_FeelConnected,SS_notice_opportunities as notice_opportunities,
      '' as Num_ContactInfo, '' as Num_Communicated
      , SS_NumConvos_LastWk_Clean_Trim2SD as NumConvos_LastWk_Clean_Trim2SD
      , SS_NumConvos_LastWk_Clean_Trim25SD as NumConvos_LastWk_Clean_Trim25SD
      , SS_NumConvos_LastWk_Clean_Trim3SD as NumConvos_LastWk_Clean_Trim3SD
    from dfs2_general_filtered
    union 
    select 2 as Time, GooseChaseId_Fixed, Uni,T_Condition2,T_Condition3,
      SS_Demog_Age,SS_Demog_SexFemale,SS_Trait_SocConn_Avg7,SS_Trait_SHS_Avg7,
      SS_SocialCuriosity_Avg,SS_InteractionAnxiety_Avg,SS_Shy_Avg,SS_SelfEsteem_Avg,
      ES_Predict_NumToApp_Clean,ES_Predict_Reject_Clean,ES_Predict_ConvoLen_Clean,
      ES_Predict_ValAroConn_Avg,
      ES_General_Ability_Avg7,
      ES_HardStart,ES_HardStart_rev,ES_HardMaintain,ES_HardMaintain_rev,ES_HardEnd,ES_HardEnd_rev,
      ES_General_Awk_Avg7,ES_General_Enj_Avg7, ES_General_PartnerPerception_Avg7,'',
      ES_Strangers_Trust,ES_Strangers_FeelWarmly,ES_Strangers_FeelConnected,ES_notice_opportunities,
      ES_Num_ContactInfo_Clean,ES_Num_Communicated_Clean
      ,'','',''
    from dfs2_general_filtered
    union 
      select 3 as Time, GooseChaseId_Fixed, Uni,T_Condition2,T_Condition3,
      SS_Demog_Age,SS_Demog_SexFemale,SS_Trait_SocConn_Avg7,SS_Trait_SHS_Avg7,
      SS_SocialCuriosity_Avg,SS_InteractionAnxiety_Avg,SS_Shy_Avg,SS_SelfEsteem_Avg,
      FU_Predict_NumToApp_Clean,FU_Predict_Reject_Clean,FU_Predict_ConvoLen_Clean,
      FU_Predict_ValAroConn_Avg,
      FU_General_Ability_Avg7,
      FU_HardStart,FU_HardStart_rev,FU_HardMaintain,FU_HardMaintain_rev,FU_HardEnd,FU_HardEnd_rev,
      FU_General_Awk_Avg7,FU_General_Enj_Avg7, FU_General_PartnerPerception_Avg7,'',
      FU_Strangers_Trust,FU_Strangers_FeelWarmly,FU_Strangers_FeelConnected,FU_notice_opportunities,
      '','',
      FU_NumConvos_LastWk_Clean_Trim2SD,FU_NumConvos_LastWk_Clean_Trim25SD,FU_NumConvos_LastWk_Clean_Trim3SD
    from dfs2_general_filtered")
nrow(dfs2_general_filtered_long)
```

```{r}
#把实验组别和时间变量变成有标签的因子变量

#实验组别T_Condition2："0"=对照组，"1"=干预组
dfs2_general_filtered_long$T_Condition2 <- as.factor(dfs2_general_filtered_long$T_Condition2)
dfs2_general_filtered_long$T_Condition2 <- revalue(dfs2_general_filtered_long$T_Condition2, c("0"="control","1"="treatment"))

#创建一个新的变量Timei，是 Time 的数值编码版本，用于需要连续时间处理的模型
dfs2_general_filtered_long$Timei <- as.numeric(dfs2_general_filtered_long$Time)

#时间变量Time："1"="start", "2"="end", "3"="followup"
dfs2_general_filtered_long$Time <- as.factor(dfs2_general_filtered_long$Time)
dfs2_general_filtered_long$Time <- revalue(dfs2_general_filtered_long$Time, c("1"="start", "2"="end", "3"="followup"))
```

```{r}
#daily数据处理#

#daily数据筛选
#非试点数据（正式实验）；完成至少4天任务；没有说谎；研究者判断为有效数据（排除了自述重大事件影响状态的被试）
dfs2_daily_filtered <- sqldf("select * from dfs2_daily 
             where T_Pilot_0No1Yes=0 #只保留非试验性（pilot）数据
             AND T_Completed_NumDays>=4 #只保留完成至少 4 天任务的参与者
             AND ES_Honesty_NoMission=0 #排除没有完成诚实任务的参与者
             AND SS_Include_NoYes=1") #只保留通过质量筛选的参与者
nrow(dfs2_daily_filtered) #检测筛选后的样本数量

#将评分类型RatingType和天数Day转换为因子

#RatingType 变量从数字类型转换为因子
dfs2_daily_filtered$RatingType <- as.factor(dfs2_daily_filtered$RatingType)
#重命名因子水平为更有意义的标签
dfs2_daily_filtered$RatingType <- revalue(dfs2_daily_filtered$RatingType, c("0"="prediction", "1"="actual"))
#确保Day变量为数值型，连续变量用于建模
dfs2_daily_filtered$Day <- as.numeric(dfs2_daily_filtered$Day)
#创建一个新的变量Dayf，是Day的因子版本
dfs2_daily_filtered$Dayf <- as.factor(dfs2_daily_filtered$Day)
#重命名Day因子的标签为具体日子
dfs2_daily_filtered$Dayf <- revalue(dfs2_daily_filtered$Dayf, c("1"="Monday", "2"="Tuesday", "3"="Wednesday", "4"="Thursday", "5"="Friday"))

```
#数据分析，首先分析general data
```{r}
#####################################################
# General: Change in Fear of Rejection
#####################################################

#建立一个广义线性混合模型GLMM，使用负二项分布
#考虑组别和时间的交互作用，将每个参与者作为随机截距，考虑起始时的个体差异
mnb.general.reject <- glmer.nb(formula = Reject ~ T_Condition2*Time + (1|GooseChaseId_Fixed), data = dfs2_general_filtered_long)
#模型摘要
summ(mnb.general.reject)


#非模型的描述性统计，按照Time和Condition进行分组
summaryBy(Reject ~ Time + T_Condition2, data = dfs2_general_filtered_long, FUN=c(mean,sd), na.rm=TRUE)

#计算边际均值，基于模型的预测均值（不是原始样本均值）
means.general.reject <- emmeans(mnb.general.reject, specs = ~ Time*T_Condition2, data=dfs2_general_filtered_long, type = "response")
means.general.reject

#成对比较，对所有 Time × Condition 的组合进行成对比较，一共有15个比较对
#使用Wald Z检验进行成对比较
lsmlist <- contrast(means.general.reject, method = "pairwise", adjust = "none")

#保留最关心的7对进行对比
#(6)end control vs. followup control,关注control 组随时间变化
#(7)end control vs. start treatment,关注基线对比
#(8)end control vs. end treatment,关注干预效果
#(10)followup control vs. start treatment,关注长期效果
#(12)followup control vs. followup treatment,关注干预延续性
#(13)start treatment vs. end treatment,关注干预前后变化
#(14)	start treatment vs. followup treatment,关注干预延续效果
lsmlist <- lsmlist[c(6,7,8,10,12,13,14)]
#使用多变量t分布multivariate t（mvt)进行多重比较校正
mydiffs = update(lsmlist, pri.vars = "contrast", by.vars = NULL,adjust="mvt")
mydiffs

#计算置信区间
confint(mydiffs, adjust = "mvt")

```
#分析daily数据
```{r}
#####################################################
# Daily: Change in Fear of Rejection: Predictions vs. Experiences
#####################################################
#描述性统计
#计算被拒绝次数在不同评分类型（预测 vs 实际）下的描述性平均值与标准差
summaryBy(Reject_Clean ~RatingType, data = dfs2_daily_filtered, FUN=c(mean,sd), na.rm=TRUE)
#计算被拒绝次数在不同天数与评分类型（预测 vs 实际）下的描述性平均值与标准差
summaryBy(Reject_Clean ~ Day + RatingType, data = dfs2_daily_filtered, FUN=c(mean,sd), na.rm=TRUE)

#推断性统计
#使用广义线性混合模型拟合一个负二项回归模型,分析每天的被拒绝数是否受到 RatingType（预测 vs 实际）和 Day（星期几）及其交互作用的影响
mnb.daily.reject <- glmer.nb(formula = Reject_Clean ~ RatingType*Day + (1|GooseChaseId_Fixed), data = dfs2_daily_filtered)
#计算主效应、交互效应的置信区间
confint(mnb.daily.reject)
#模型摘要
summ(mnb.daily.reject,digit=4)
#计算不同 RatingType 和 Day （Day此时为连续变量，取均值）条件下的模型预测边际均值，从而比较各个条件之间的差异
means.daily.reject <- emmeans(mnb.daily.reject, specs = ~ RatingType*Day, type = "response")
means.daily.reject
#基于预测边际均值，比较不同条件下的差异
contr.all <- contrast(means.daily.reject, method = "pairwise", adjust = "none")
contr.all
#得到置信区间
confint(contr.all, adjust = "none")
#简单斜率检验
emtrends(mnb.daily.reject, ~ RatingType, var="Day") #置信区间
test(emtrends(mnb.daily.reject, ~ RatingType, var="Day")) #z值，p值

#把Day转化为因子重建模型。将 Day 设为因子（Dayf）后，每一天就可以被视为一个独立水平，以此报告每个“具体时间”（如星期几）的差异和平均数。为可视化做准备
mnb.daily.reject.categorical <- glmer.nb(formula = Reject_Clean ~ RatingType*Dayf + (1|GooseChaseId_Fixed), data = dfs2_daily_filtered)
#计算不同 RatingType 和 Day （Day此时为类别变量）条件下的模型预测边际均值，从而比较各个条件之间的差异
means.daily.reject.categorical <- emmeans(mnb.daily.reject.categorical, specs = ~ RatingType*Dayf, type = "response")
#计算不同 RatingType 条件下的模型预测边际均值，从而比较预测被拒绝数与实际被拒绝数之间的差异
means.daily.reject.categorical_RatingType <- emmeans(mnb.daily.reject.categorical, specs = ~ RatingType, type = "response")
```

#基于daily数据分析因变量会话能力Ability随干预的变化趋势（是否受到 RatingType（预测 vs 实际）和 Day（星期几）及其交互作用的影响）
```{r}
#####################################################
# Daily: Predictions vs. Experiences
# Change in Ability
#####################################################

# ability
#描述性统计
#计算 Ability_Avg7 在不同天数与评分类型（预测 vs 实际）下的描述性平均值与标准差
summaryBy(Ability_Avg7 ~ Day + RatingType, data = dfs2_daily_filtered, FUN=c(mean,sd), na.rm=TRUE)
#使用线性混合效应模型，分析每天的会话能力Ability是否受到 RatingType（预测 vs 实际）和 Day（星期几）及其交互作用的影响
#原初模型：仅考虑被试作为随机截距
lm.daily.ability1 <- lmer(formula = Ability_Avg7 ~ RatingType*Day + (1|GooseChaseId_Fixed), data = dfs2_daily_filtered)
#使用summ函数输出原初模型摘要
summ(lm.daily.ability1)
#使用confint函数计算混合模型中各个参数的置信区间
confint(lm.daily.ability1)
#将Day转化为因子重跑模型
lm.daily.ability.categorical <- lmer(formula = Ability_Avg7 ~ RatingType*Dayf + (1|GooseChaseId_Fixed), data = dfs2_daily_filtered)
means.daily.ability.categorical <- emmeans(lm.daily.ability.categorical, specs = ~ RatingType*Dayf, type = "response")
```

#本小组改编新模型
```{r}
#将 T_Condition2 列中的 0 和 1 编码转换为 -0.5 和 0.5
dfs2_daily_filtered <- dfs2_daily_filtered %>%
  mutate(R_T = recode(RatingType, "prediction" = -0.5, "actual" = 0.5))
#新模型：考虑Day 的效应（即时间趋势）在不同被试间存在显著差异
lm.daily.ability2 <- lmer(formula = Ability_Avg7 ~ R_T*Day + (1+Day|GooseChaseId_Fixed), data = dfs2_daily_filtered)
#使用summ函数输出新模型摘要
summ(lm.daily.ability2)
#使用confint函数计算混合模型中各个参数的置信区间
confint(lm.daily.ability2)
#模型比较
anova(lm.daily.ability1,lm.daily.ability2)

#使用（emmeans）获取新模型估计的预测边际均值
means.daily.ability2 <- emmeans(lm.daily.ability2, specs = ~ R_T*Day, type = "response")
means.daily.ability2

#通过 emmeans() 获得边际均值（means.daily.ability）后，对不同条件之间的差异进行事后比较（pairwise contrast），并输出其置信区间（confidence intervals）
contr.all <- contrast(means.daily.ability2, method = "pairwise", adjust = "none")
contr.all
confint(contr.all, adjust = "none")

#简单斜率检验:检验预测会话能力与实际会话能力在天数（Day）上的斜率（趋势）是否显著不同
#source for emtrends: https://stats.idre.ucla.edu/r/seminars/interactions-r/#s4b
test(emtrends(lm.daily.ability2, ~ R_T, var="Day"))

#置信区间
emtrends(lm.daily.ability2, ~ R_T, var="Day")

#把Day转化为因子重建模型。将 Day 设为因子（Dayf）后，每一天就可以被视为一个独立水平
#报告每个“具体时间点”（如星期几）的平均预测会话能力和平均实际会话能力
lm.daily.ability2.categorical <- lmer(formula = Ability_Avg7 ~ RatingType*Dayf + (1+Day|GooseChaseId_Fixed), data = dfs2_daily_filtered)
means.daily.ability2.categorical <- emmeans(lm.daily.ability2.categorical, specs = ~ RatingType*Dayf, type = "response")
print(means.daily.ability2.categorical)
```
#结果可视化
```{r}
# 图1: general-Rejection
#参与者在实验开始时、结束时、实验结束一周时的预测被拒绝人数
plot_general_reject <- ggplot(as.data.frame(means.general.reject), aes(x = Time, y = response, group=T_Condition2)) + 
  geom_line(aes(color = T_Condition2, linetype=T_Condition2)) + geom_point(aes(color = T_Condition2)) +
  geom_errorbar(aes(ymin=asymp.LCL, ymax=asymp.UCL, colour = T_Condition2), width=.1) + 
  scale_color_manual("Condition",values=c('#999999','#E69F00'),labels=c("Control","Treatment")) +
  scale_linetype_manual("Condition",values=c("dashed","solid"),labels=c("Control","Treatment")) +
  theme_classic(base_size = 15) + theme(plot.title = element_text(hjust = 0.5)) + 
  ggtitle("Perceived Likelihood of Rejection")+
  scale_x_discrete("Time",labels=c("start"="Start of\nStudy", "end"="End of\nStudy", "followup"="Follow-up\n(1 week)")) +
  scale_y_continuous(limits=c(0,1.6))

print(plot_general_reject) 
```

```{r}
#图2 daily-rejection
#参与者每日的预测被拒绝次数vs.实际被拒绝次数
plot_daily_reject <- ggplot(as.data.frame(means.daily.reject.categorical), aes(x = Dayf, y = response, group=RatingType)) +  
  geom_line(aes(color = RatingType, linetype=RatingType)) + geom_point(aes(color = RatingType)) + 
  geom_errorbar(aes(ymin=asymp.LCL, ymax=asymp.UCL, colour = RatingType), width=.1) +
  scale_color_manual("Rating Type",values=c('dodgerblue4','#E69F00'),labels=c("Predicted","Actual")) +
  scale_linetype_manual("Rating Type",values=c("dashed","solid"),labels=c("Predicted","Actual")) +
  theme_classic(base_size = 15) + theme(plot.title = element_text(hjust = 0.5)) + 
  ggtitle("Predicted and Actual Rejection")+
  scale_x_discrete("Time",labels=c("Monday"="Mon", "Tuesday"="Tues", "Wednesday"="Wed", "Thursday"="Thurs", "Friday"="Fri")) +
  scale_y_continuous(limits=c(0,1))
# 输出绘图
print(plot_daily_reject)
```


```{r}
#图3 daily-ability
#参与者每日的预测对话能力vs.实际对话能力
plot_daily_ability <- ggplot(as.data.frame(means.daily.ability.categorical), aes(x = Dayf, y = emmean, group=RatingType)) +  
  geom_line(aes(color = RatingType, linetype=RatingType)) + geom_point(aes(color = RatingType)) + 
  geom_errorbar(aes(ymin=lower.CL, ymax=upper.CL, colour = RatingType), width=.1) +
  scale_color_manual("Rating Type",values=c('dodgerblue4','#E69F00'),labels=c("Predicted","Actual")) +
  scale_linetype_manual("Rating Type",values=c("dashed","solid"),labels=c("Predicted","Actual")) +
  theme_classic(base_size = 15) + theme(plot.title = element_text(hjust = 0.5)) + 
  ggtitle("Predicted and Actual Conversational Ability")+
  scale_x_discrete("Time",labels=c("Monday"="Mon", "Tuesday"="Tues", "Wednesday"="Wed", "Thursday"="Thurs", "Friday"="Fri")) +
  scale_y_continuous(limits=c(3,6))
# 输出绘图
print(plot_daily_ability)
```



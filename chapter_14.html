<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>chapter_14.knit</title>
    <meta charset="utf-8" />
    <meta name="author" content="" />
    <script src="libs/header-attrs-2.21/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/Font_Style.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class: center, middle
&lt;span style="font-size: 60px;"&gt;第十四章&lt;/span&gt; &lt;br&gt;
&lt;span style="font-size: 50px;"&gt;统计检验力分析 &lt;br&gt;

&lt;br&gt;
&lt;br&gt;
&lt;span style="font-size: 30px;"&gt;胡传鹏&lt;/span&gt; &lt;br&gt;
&lt;span style="font-size: 30px;"&gt;2023/06/05&lt;/span&gt; &lt;br&gt;

---

# &lt;h1 lang="zh-CN"&gt;什么是统计检验力&lt;/h1&gt;
**统计检验力（统计功效, statistical power）**: 假设检验中正确拒绝虚无假设的概率。&lt;br&gt;
&lt;br&gt;
`\(1 - \beta = P(sig \ | \ H_1)\)`
&lt;br&gt;
.center[&lt;img src="./picture/chp14/beta.png" width="60%" height="50%"&gt;]

---

统计检验力主要由三个因素决定：&lt;br&gt;

- 效应量(effect size)
- 一类错误率(Type 1 error, `\(\alpha\)`)
- 样本量(sample size)

效应量、一类错误率、效应量越大，统计功检验力越高；相反则更低。

---
# &lt;h1 lang="zh-CN"&gt;其他统计量与统计检验力的关系——以单样本*t*检验为例&lt;/h1&gt;
---
## &lt;h2 lang="zh-CN"&gt;效应量与统计检验力的关系——以单样本*t*检验为例&lt;/h2&gt;

在本次模拟中，样本量固定为$ n = 20$，一类错误率固定为$\alpha = 0.05$


```r
rm(list = ls())
if (!requireNamespace("pacman", quietly = TRUE)) {
  install.packages("pacman") }             # 检查是否已安装 pacman, 如果未安装，则安装包

pacman::p_load("tidyverse", "faux", "pwr", "MASS", "afex") # 使用p_load来载入需要的包
```



```r
effect_size &lt;- seq(0.1, 1, 0.1) # 生成10个效应量，从0.1到1，间隔为0.1

len_power &lt;- length(effect_size) # 获取生成效应量的长度，即10

idx &lt;- 0 # 设置一个idx变量作为标识符，后续用于定位

power &lt;- numeric(len_power) # 生成与len_power长度一致的0，便于后续修改

for (i in effect_size) {     # 遍历所有的效应量
  p &lt;- numeric(5000)        # 生成5000个长度的列表，用于储存p值
  idx &lt;- idx + 1             # 每运行一次for循环，idx就加1
  for (j in 1:5000) { 
    # 在遍历效应量的基础上运行5000次计算p值，用于后续计算power
    # 生成20个服从均值为某一效应量，标准差为1的正态分布的样本
    x &lt;- rnorm(n = 20, mean = i, sd = 1) 
    p[j] &lt;- t.test(x)$p.value # 储存p值
  }
  
  power[idx] &lt;- sum(p &lt; 0.05) / 5000 # 计算p值小于0.05的个数并除5000计算power
}

df_sim1 &lt;- data.frame(effect_size = effect_size, power = power)
```

---


```r
df_sim1 %&gt;%
  ggplot2::ggplot(aes(x = effect_size, y = power)) + 
  ggplot2::geom_point(size = 5) +
  ggplot2::geom_line() +
  ggplot2::labs(title = "Fixed sample size and alpha value",
                x = "Effect size (Cohen's d)",
                y = "Statistical power") + 
  papaja::theme_apa()
```

![](chapter_14_files/figure-html/plot effect size and power-1.png)&lt;!-- --&gt;

---

有许多R包可用于计算统计检验力，如`pwr`


```r
pwr.t.test(
  n = 20, d = 0.2, sig.level = 0.05,
  type = "one.sample", alternative = "two.sided"
)[["power"]]
```

```
## [1] 0.1359563
```

---

可以使用map函数结合`pwr`来计算不同效应量下的统计检验力


```r
map_dbl(effect_size, ~ pwr.t.test(
  n = 20, d = .x,
  sig.level = 0.05,
  type = "one.sample",
  alternative = "two.sided"
)[["power"]])
```

```
##  [1] 0.07094116 0.13595629 0.24708909 0.39699383 0.56450442 0.72100510
##  [7] 0.84350588 0.92389876 0.96815164 0.98859129
```

---

## &lt;h2 lang="zh-CN"&gt; `\(\alpha\)`与统计检验力的关系 &lt;/h2&gt;
在本次模拟中，样本量固定为20，效应量固定为0.5


```r
alpha &lt;- c(0.001, 0.01, 0.05, 0.1) # 生成5个alpha值
len_alpha &lt;- length(alpha)         # 获取生成alpha向量的长度，即5

idx &lt;- 0 # 设置一个idx变量作为标识符，后续用于定位

power &lt;- numeric(len_alpha) # 生成与len_alpha长度一致的0，便于后续修改

for (i in alpha) {      # 遍历所有的效应量
  p &lt;- numeric(5000)   # 生成5000个长度的列表，用于储存p值
  idx &lt;- idx + 1        # 每运行一次for循环，idx就加1
  for (j in 1:5000) { 
    # 在遍历效应量的基础上运行5000次计算p值，用于后续计算power
    x &lt;- rnorm(n = 20, mean = 0.5, sd = 1) 
    # 生成20个服从均值为某一效应量，标准差为1的正态分布的样本
    p[j] &lt;- t.test(x)$p.value # 储存p值
  }
  power[idx] &lt;- sum(p &lt; i) / 5000 # 计算p值小于alpha的个数并除5000计算power
}

df_sim2 &lt;- data.frame(alpha = alpha, power = power)
```

---


```r
df_sim2 %&gt;%
  ggplot2::ggplot(aes(x = alpha, y = power)) + 
  ggplot2::geom_point(size = 5) +
  ggplot2::geom_line() +
  ggplot2::labs(title = "Fixed sample size and effect size",
                x = "alpha",
                y = "Statistical power") + 
  papaja::theme_apa()
```

![](chapter_14_files/figure-html/plot alpha and power-1.png)&lt;!-- --&gt;

---

```r
map_dbl(alpha, ~ pwr.t.test(
  n = 20, d = 0.5,
  sig.level = .x,
  type = "one.sample",
  alternative = "two.sided"
)[["power"]])
```

```
## [1] 0.08739216 0.29734608 0.56450442 0.69522018
```

---
## &lt;h2 lang="zh-CN"&gt;样本量与统计检验力的关系&lt;/h2&gt;


```r
sample_size &lt;- seq(10, 100, 10)
# 生成10个效应量，从0.1到1，间隔为0.1
len_n &lt;- length(sample_size) # 获取生成效应量的长度，即10
idx &lt;- 0 # 设置一个idx变量作为标识符，后续用于定位
power &lt;- numeric(len_n) # 生成与len_n长度一致的0，便于后续修改
for (i in sample_size) { # 遍历所有的效应量
  p &lt;- numeric(5000) # 生成5000个长度的列表，用于储存p值
  idx &lt;- idx + 1 # 每运行一次for循环，idx就加1
  # 在遍历效应量的基础上运行5000次计算p值，用于后续计算power
  for (j in 1:5000) { 
    x &lt;- rnorm(n = i, mean = 0.5, sd = 1) 
    # 生成20个服从均值为某一效应量，标准差为1的正态分布的样本
    p[j] &lt;- t.test(x)$p.value # 储存p值
  }
# 计算p值小于0.05的个数并除5000计算power
  power[idx] &lt;- sum(p &lt; 0.05) / 5000 
}

df_sim3 &lt;- data.frame(sample_size = sample_size, power = power)
```

---


```r
df_sim3 %&gt;%
  ggplot2::ggplot(aes(x = sample_size, y = power)) + 
  ggplot2::geom_point(size = 5) +
  ggplot2::geom_line() +
  ggplot2::labs(title = "Fixed effect size and alpha",
                x = "Sample size",
                y = "Statistical power") + 
  papaja::theme_apa()
```

![](chapter_14_files/figure-html/plot sample size and power-1.png)&lt;!-- --&gt;

---


```r
map_dbl(sample_size, ~ pwr.t.test(
  n = .x, d = 0.5,
  sig.level = 0.05,
  type = "one.sample",
  alternative = "two.sided"
)[["power"]])
```

```
##  [1] 0.2931756 0.5645044 0.7539647 0.8693981 0.9338976 0.9677886 0.9847848
##  [8] 0.9929987 0.9968496 0.9986097
```

---
# &lt;h1 lang="zh-CN"&gt;G*Power中的结果是如何计算的&lt;/h1&gt;

在使用GPower时，我们通常需要在软件中填写两组之间的差异Cohen's *d*（如 Cohen's *d* = 0.5）。

假设我们有两组被试分别进行了某些测验，每组共10名被试，两组被试的均值分别为0.5和0，标准差为1。通过之前课程学习到的计算*d*的公式：

`$$Cohen's \  d_s = \frac{X_1 - X_2}{\sqrt{SD_{pool}}} = \frac{X_1 - X_2}{\sqrt{\frac{(n_1 -1)SD_1^2 + (n_2-1)SD_2^2)}{n_1+n2-2}}}$$`
我们可以计算出*d*为：
`$$Cohen's \  d_s = \frac{0.5 - 0}{\sqrt{\frac{(10 -1)1^2 + (10-1)1^2)}{10+10-2}}}=0.5$$`
---

代码实现：


```r
n1 &lt;- 10
n2 &lt;- 10
m1 &lt;- 0.5
m2 &lt;- 0
sd1 &lt;- 1
sd2 &lt;- 1
group1 &lt;- rnorm(n1, m1, sd1) # 生成n1个，以m1为均值，sd1位标准差服从正态分布的样本
group2 &lt;- rnorm(n2, m2, sd2)
print(group1)
```

```
##  [1]  2.08568685 -0.30999007  0.27446153  0.59587669  1.06690530 -0.17633938
##  [7]  1.21959538 -0.60419180  1.45087405 -0.07754571
```

```r
print(group2)
```

```
##  [1] -0.049405457 -0.457898358  0.995300320  1.088889798 -0.755586746
##  [6]  2.061677387 -0.145812397  0.249998684  0.450576670 -0.004948325
```

---
*t*检验结果显示，未达到统计学意义上的显著性水平


```r
t.test(group1, group2)
```

```
## 
## 	Welch Two Sample t-test
## 
## data:  group1 and group2
## t = 0.54486, df = 17.958, p-value = 0.5926
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.5977474  1.0162557
## sample estimates:
## mean of x mean of y 
## 0.5525333 0.3432792
```

---

为了进行统计检验力分析，我们需要模拟很多次并观察是否每次在给定效应量和一类错误率时的显著性水平。我们以传统上80%的统计检验力为标准，对比当前模拟的结果。


```r
sim &lt;- 5000 # 进行5000次模拟
n1 &lt;- 10
n2 &lt;- 10
m1 &lt;- 0.5
m2 &lt;- 0
sd1 &lt;- 1
sd2 &lt;- 1
pvals &lt;- c()
cohen_ds &lt;- c()

for (i in 1:sim) {
  group1 &lt;- rnorm(n1, m1, sd1)
  group2 &lt;- rnorm(n2, m2, sd2)

  pvals[i] &lt;- t.test(group1, group2)$p.value
  
  cohen_ds[i] &lt;- (mean(group1)-mean(group2))/
    (sqrt(((n1-1)*sd(group1)^2 + (n2-1) * sd(group2)^2) / 
            (n1+n2-2)))
}
```

---
可以看到，这里我们的统计检验力只有：


```r
sum(pvals &lt; 0.05) / sim
```

```
## [1] 0.1886
```

```r
mean(cohen_ds)
```

```
## [1] 0.5249331
```

---

与pwr包对比


```r
pwr.t.test(n = 10, d = 0.5, sig.level = 0.05, type = "two.sample")
```

```
## 
##      Two-sample t test power calculation 
## 
##               n = 10
##               d = 0.5
##       sig.level = 0.05
##           power = 0.1850957
##     alternative = two.sided
## 
## NOTE: n is number in *each* group
```

---
与G*Power对比

.center[&lt;img src="./picture/chp14/gpower2sample.png" width="60%"&gt;]
---

可以看到模拟的结果与其他两个工具包/软件的结果很相似。

---

接下来我们可以改进一下代码，在给定效应量，和一类错误水平的情况下，被试数量到达多少时，统计检验力达到80%。

**sample size planning?**


```r
sim &lt;- 5000 # 模拟次数为5000
power &lt;- c() # 储存power值
d_mean &lt;- c() # 储存效应量
n1 &lt;- 10 # 第一组被试初识数量为10名
n2 &lt;- 10
m1 &lt;- 0.5
m2 &lt;- 0
sd1 &lt;- 1
sd2 &lt;- 1
increase_num &lt;- 0 # 从0开始计算power，即从每组10人开始计算
```

---


```r
for (i in 1:5000000) { # for循环给定一个极大的数进行遍历
  pvals &lt;- c()          # 储存后续每一次模拟的p值
  cohen_ds &lt;- c()       # 储存每一次模拟的d值
  for (j in 1:sim) {    # 开始对每一个组数量进行模拟
    group1 &lt;- rnorm(n1, m1, sd1)
    group2 &lt;- rnorm(n2, m2, sd2)
    pvals[j] &lt;- t.test(group1, group2)$p.value
    cohen_ds[j] &lt;- (mean(group1) - mean(group2)) / (sqrt(((n1 - 1) * sd(group1)^2 + (n2 - 1) * sd(group2)^2) / (n1 + n2 - 2)))
  }
  power[increase_num + 1] &lt;- sum(pvals &lt; 0.05) / sim # 储存power值，由于无法添加索引0的值，所以先加1
  d_mean[increase_num + 1] &lt;- mean(cohen_ds)
  n1 &lt;- n1 + 1  # 每次计算完power后，对每组加1
  n2 &lt;- n2 + 1
  if (power[increase_num + 1] &gt;= 0.8) {
    break      # 当power达到0.8时停止运行
  }
  increase_num &lt;- increase_num + 1                  # 增加的被试加1
}
```

---
统计检验力随着样本量增加的变化


```r
plot(10:(increase_num + 10), power, 
     xlab = "Number of subjects each group", 
     ylab = "power", ylim = c(0, 1.0))
abline(h = 0.8, col = "red")
```

![](chapter_14_files/figure-html/unnamed-chunk-12-1.png)&lt;!-- --&gt;

---

效应量随着样本量增加的变化(?)


```r
plot(10:(increase_num + 10), d_mean, 
     xlab = "Number of subjects each group", 
     ylab = "Cohen's d", ylim = c(0.2, 0.8))
abline(h = 0.5, col = "red")
```

![](chapter_14_files/figure-html/unnamed-chunk-13-1.png)&lt;!-- --&gt;

---

模拟达到80%统计检验力所需要的样本数量为每组：


```r
print(10 + increase_num)
```

```
## [1] 63
```

与G*Power对比：
.center[&lt;img src="./picture/chp14/gpowersamplesize.png" width="50%"&gt;]

---

## &lt;h2 lang="zh-CN"&gt;生成前后测数据——配对样本*t*检验&lt;/h2&gt;

前后测数据通常之间存在一定程度的相关

为了生成前后测数据，我们可以通过`MASS`包中的`mvrnorm()`函数生成。

首先我们设定被试数量为100，前测的均值为0，后测均值为1，标准差均为1，两次测量结果的相关为0.3。


```r
n &lt;- 100
test1_mean &lt;- 0
test2_mean &lt;- 1
test1_sd &lt;- 1
test2_sd &lt;- 1
rho &lt;- 0.3
```

---
然后，我们根据公式生成一个方差协方差矩阵
.center[&lt;img src="./picture/chp14/cov.png" width="50%"&gt;]

- https://en.wikipedia.org/wiki/Multivariate_normal_distribution

---
代码实现：


```r
sigma &lt;- matrix(c(test1_sd^2, test1_sd * test2_sd * rho, 
                  test1_sd * test2_sd * rho, test2_sd^2), 
                ncol = 2)

df &lt;- data.frame(mvrnorm(
  n = n, mu = c(test1_mean, test2_mean),
  Sigma = sigma
))
head(df)
```

```
##           X1         X2
## 1  0.5343640 3.35213375
## 2  0.3436207 0.44373099
## 3  0.2947831 0.44299061
## 4  1.2514679 0.68543551
## 5 -1.9914871 0.01601588
## 6  1.2019885 2.35744657
```

---
我们可以简单检查一下模拟结果:


```r
cor(df$X1, df$X2)
```

```
## [1] 0.3541874
```

```r
mean(df$X1)
```

```
## [1] -0.08473641
```

```r
mean(df$X2)
```

```
## [1] 1.1175
```

---
最后，我们可以根据计算cohen'd的公式确定一下配对数据的效应量，然后进行统计检验力分析，这里与G*Power一致采用：

 
`$$Cohen's d_{z} = \frac{M_{diff}}{SD_{diff}}$$`


```r
library(MASS)
sim &lt;- 1000 # 模拟次数为5000

power &lt;- c() # 储存power值
d_mean &lt;- c()
cor_mean &lt;- c()
n &lt;- 10 # 第一组被试初识数量为10名
m1 &lt;- 10
m2 &lt;- 10.5
sd1 &lt;- 1
sd2 &lt;- 2
rho &lt;- 0.3
increase_num &lt;- 0 # 从0开始计算power，即从每组10人开始计算
```

---


```r
for (i in 1:500000) { # for循环给定一个极大的数进行遍历
  pvals &lt;- c() # 储存后续每一次模拟的p值
  ds &lt;- c()
  cors &lt;- c()
  for (j in 1:sim) { # 开始对每一个组数量进行模拟
    sigma &lt;- matrix(c(sd1^2, sd1 * sd2 * rho, 
                      sd1 * sd2 * rho, sd2^2), 
                    ncol = 2)
    df &lt;- data.frame(mvrnorm(
      n = n, mu = c(m1, m2),
      Sigma = sigma
    ))
    pvals[j] &lt;- t.test(df$X1, df$X2, paired = TRUE)$p.value
    ds &lt;- (mean(df$X1) - mean(df$X2)) / sd(df$X1 - df$X2)
    cors[j] &lt;- cor(df$X1, df$X2)
  }
  power[increase_num + 1] &lt;- sum(pvals &lt; 0.05) / sim 
  d_mean[increase_num + 1] &lt;- mean(ds)
  cor_mean[increase_num + 1] &lt;- mean(cors)
  n &lt;- n + 1 # 每次计算完power后，对每组加1
  if (power[increase_num + 1] &gt;= 0.8) {
    break # 当power达到0.8时停止运行
  }
  increase_num &lt;- increase_num + 1 # 增加的被试加1
}
```

---


```r
plot(10:(increase_num + 10), power, 
     xlab = "Number of subjects", 
     ylab = "power", ylim = c(0, 1.0))
abline(h = 0.8, col = "red")
```

![](chapter_14_files/figure-html/unnamed-chunk-20-1.png)&lt;!-- --&gt;

---


```r
plot(x = 10:(increase_num + 10), 
     y = cor_mean, ylim = c(0, 0.6), 
     ylab = "correlation", 
     xlab = "Number of subjects")
```

![](chapter_14_files/figure-html/unnamed-chunk-21-1.png)&lt;!-- --&gt;

---

总共需要样本量为：


```r
print(10 + increase_num)
```

```
## [1] 118
```

---

与G*Power对比：
- 首先先生成一个拥有相同参数的很大样本量的数据，用于计算总体水平的Cohen's dz，并将该值输入到G*Power中


```r
set.seed(124)
n &lt;- 500000 # 第一组被试初识数量为10名
m1 &lt;- 10
m2 &lt;- 10.5
sd1 &lt;- 1
sd2 &lt;- 2
rho &lt;- 0.3

sigma &lt;- matrix(c(sd1^2, sd1 * sd2 * rho,
                  sd1 * sd2 * rho, sd2^2), 
                ncol = 2)

df &lt;- data.frame(mvrnorm(
  n = n, mu = c(m1, m2),
  Sigma = sigma
))

dz &lt;- (mean(df$X1) - mean(df$X2)) / sd(df$X1 - df$X2)
print(dz)
```

```
## [1] -0.2578324
```

---

.center[&lt;img src="./picture/chp14/paired.png" width="50%"&gt;]

---

# &lt;h1 lang="zh-CN"&gt;如何计划分析方法：以ANOVA为例&lt;/h1&gt;

---

## &lt;h2 lang="zh-CN"&gt;生成假数据&lt;/h2&gt;
在规划样本量时通常使用G\*Power进行先验统计检验力分析 (*a-priori* power analysis)。使用使用工具进行先验统计检验力分析非常方便，但是灵活性不高。在进行更复杂的检验时，我们可以使用前面使用过模拟的方式进行。

假设我们要进行一个2\*2被试内设计的实验，根据前人的研究我们设定groupA和groupB的四个水平的均值分别为A1B1 = 100, A1B2 = 80, A2B1 = 200, A2B2 = 250。

并且，我们主要关注和检验groupA和groupB的交互作用
---

### &lt;h3 lang="zh-CN"&gt;代码实现&lt;/h3&gt;
使用`faux`包生成2*2被试内的模拟数据

---


```r
df_aov &lt;- sim_design(
  n = 50, # 生成50名被试
  within = list(groupA = c("A1", "A2"), groupB = c("B1", "B2")), # 生成被试内因子的列表
  
  mu = c(100, 80, 200, 250), # 设置变量的均值
  
  sd = c(A1 = 20, A2 = 10, B1 = 50, B2 = 90), # 设置变量的标准差
  
  long = TRUE,  # 输出长数据形式
  
  dv = "score", # 因变量命名为score
  plot = TRUE   # 显示图
)
```

![](chapter_14_files/figure-html/unnamed-chunk-24-1.png)&lt;!-- --&gt;

```r
head(df_aov)
```

```
##    id groupA groupB     score
## 1 S01     A1     B1 148.03321
## 2 S02     A1     B1 103.66462
## 3 S03     A1     B1 124.13556
## 4 S04     A1     B1 113.45001
## 5 S05     A1     B1  57.60605
## 6 S06     A1     B1  71.01715
```

---

### &lt;h3 lang="zh-CN"&gt;检查数据&lt;/h3&gt;
我们检查一下模拟生成的数据


```r
df_aov %&gt;%
  group_by(groupA, groupB) %&gt;%
  summarise(
    m = mean(score),
    sd = sd(score)
  )
```

```
## `summarise()` has grouped output by 'groupA'. You can override using the
## `.groups` argument.
```

```
## # A tibble: 4 × 4
## # Groups:   groupA [2]
##   groupA groupB     m    sd
##   &lt;fct&gt;  &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;
## 1 A1     B1      99.1 21.9 
## 2 A1     B2      80.8  9.46
## 3 A2     B1     202.  44.4 
## 4 A2     B2     246.  75.6
```

---
### &lt;h3 lang="zh-CN"&gt;计算交互项p值&lt;/h3&gt;

使用`afex`包对数据进行重复测量方差分析，并输出交互项的*p*值


```r
aov &lt;- aov_ez(id = "id", dv = "score", within = c("groupA", "groupB"), data = df_aov)
aov
```

```
## Anova Table (Type 3 tests)
## 
## Response: score
##          Effect    df     MSE          F  ges p.value
## 1        groupA 1, 49 2016.88 446.18 *** .690   &lt;.001
## 2        groupB 1, 49 2078.12     3.76 + .019    .058
## 3 groupA:groupB 1, 49 2259.62  21.02 *** .105   &lt;.001
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1
```

```r
aov[["anova_table"]][["Pr(&gt;F)"]][3]
```

```
## [1] 3.155556e-05
```


```r
aov[["anova_table"]][["Pr(&gt;F)"]][3]
```

```
## [1] 3.155556e-05
```

---
## &lt;h2 lang="zh-CN"&gt;基于模拟的统计检验力分析&lt;/h2&gt;
进行统计检验力分析


```r
sim &lt;- 1000        # 模拟次数为1000

power &lt;- c()       # 储存power值
n &lt;- 5             # 第一组被试初识数量为10名
increase_num &lt;- 0  # 从0开始计算power，即从每组10人开始计算
```

---


```r
for (i in 1:5000000) { # for循环给定一个极大的数进行遍历
  pvals &lt;- c()          # 储存后续每一次模拟的p值
  for (j in 1:sim) {    # 开始对每一个组数量进行模拟
    df_aov &lt;- sim_design(
      n = n, 
      within = list(groupA = c("A1", "A2"), groupB = c("B1", "B2")),
      mu = c(100, 80, 200, 250),
      sd = c(A1 = 20, A2 = 10, B1 = 50, B2 = 90),
      long = TRUE,
      dv = "score",
      plot = FALSE 
    )
    aov &lt;- aov_ez(id = "id", dv = "score", within = c("groupA", "groupB"), data = df_aov)
    pvals[j] &lt;- aov[["anova_table"]][["Pr(&gt;F)"]][3]
  }
  power[increase_num + 1] &lt;- sum(pvals &lt; 0.05) / sim 
  n &lt;- n + 1 # 每次计算完power后，对每组加1
  if (power[increase_num + 1] &gt;= 0.8) {
    break   # 当power达到0.8时停止运行
  }
  increase_num &lt;- increase_num + 1 # 增加的被试加1
}
```

---


```r
plot(5:(increase_num + 5), power, 
     xlab = "Number of subjects", 
     ylab = "power", ylim = c(0, 1.0))
abline(h = 0.8, col = "red")
```

![](chapter_14_files/figure-html/unnamed-chunk-30-1.png)&lt;!-- --&gt;

---
我们一共需要的样本量为：


```r
print(5 + increase_num)
```

```
## [1] 20
```

---
# &lt;h1 lang="zh-CN"&gt;统计检验力分析小结&lt;/h1&gt;

- 效应量、一类错误率、样本量在控制其他因素的情况下越大，统计检验力越高

- 可以通过模拟进行样本量规划

- 明确感兴趣的效应是进行统计检验力分析的重要步骤

---

# &lt;h1 lang="zh-CN"&gt;推荐阅读&lt;/h1&gt;
- Daniël Lakens; Sample Size Justification. *Collabra: Psychology* 5 January 2022; 8 (1): 33267. doi: https://doi.org/10.1525/collabra.33267
- DeBruine LM, Barr DJ. Understanding Mixed-Effects Models Through Data Simulation. *Advances in Methods and Practices in Psychological Science*. 2021;4(1). doi:10.1177/2515245920965119

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
